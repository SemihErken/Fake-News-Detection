{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c748cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from tqdm import tqdm \n",
    "import re \n",
    "import nltk\n",
    "import pickle\n",
    "#nltk.download('punkt') \n",
    "#nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62161548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('spacesRemoved.csv')\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import * \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'], data['class'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9e4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'vectorizator.sav'\n",
    "vectorizationTool = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aefe3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizationTool.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a312db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33216, 197383)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c3f5934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11072, 197383)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = vectorizationTool.transform(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "903635dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "modelNB = MultinomialNB()\n",
    "\n",
    "chunk_size = 1000  \n",
    "for i in range(0, x_train.shape[0], chunk_size):\n",
    "    x_chunk = x_train[i:i+chunk_size]\n",
    "    y_chunk = y_train[i:i+chunk_size]\n",
    "\n",
    "    modelNB.partial_fit(x_chunk, y_chunk, classes=np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e18b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'NBModelData01.sav'\n",
    "pickle.dump(modelNB, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9e181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'NBModelData01.sav'\n",
    "loadedNB = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed2b0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputToBeTest = [\n",
    "'the politicians using monuments history bargaining chips gain votes it sickening see back forth cowardly bunch lily livered sellouts would rather win seat fight people want yes people want keep incredible statues carvings anyone half brain knows never erase past ever if erase history pat buchananit heartbreaking see pieces history torn apart removed gather dust somewhere what wrong politicians georgia bowing liberal elites stand relatives black white fought civil war shame youpandering for votes using our monuments as collateral democratic gubernatorial candidate stacey abrams called removal giant carving depicts three confederate war leaders face stateowned stone mountain saying remains blight state removed we must never celebrate defended slavery tried destroy union abrams said series tweets posted early tuesday response deadly violence sparked white supremacist groups charlottesville varemoving faces jefferson davis robert e lee stonewall jackson would take monster sandblaster require change state law the georgia code clear mandate memorial saying preserved protected time tribute bravery heroism citizens state suffered died cause lawmakers civil rights groups called removal confederate symbols memorial years after 2015 shooting deaths nine black worshipers white supremacist charleston several legislators pushed boycott rebel flags site come downgeorgia leaders embraced recent changes distance state rebel historygov nathan deal quietly struck confederate memorial day state official holiday calendar removed statue segregationist leader state grounds stateissued license plates featuring rebel emblem altered though slightly statues paintings confederate leaders statehouse facing fresh criticism and state set unveil statue martin luther king jr outside capitol monthfour highprofile republicans race several critical stance lt gov casey cagle said state taken great strides add exhibits give inclusive view civil war instead dividing georgians inflammatory rhetoric political gain said work together add history take if you think this won t snowball into more destruction of our history just check out what happened in north carolina yesterday crazed protesters pull down confederate statue durham what next the guillotines videowe hearing lexington kentucky mayor jumping bandwagon take confederate statues via ajc']\n",
    "vectorizedInput = vectorizationTool.transform(InputToBeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff9cad99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 197383)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizedInput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b12a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = loadedNB.predict(vectorizedInput)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ce953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
